{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b45c18d8",
   "metadata": {},
   "source": [
    "# Render a satellite image (required before prediction or training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d63acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import render_raster\n",
    "\n",
    "render_raster(\n",
    "    input_tif=\"data/test_raster_raw.tif\",\n",
    "    output_tif=\"data/test_raster_rendered.tif\",\n",
    "    rgb_bands=[1,2,3], # bands are in the correct order for RGB (e.g., 1=Red, 2=Green, 3=Blue)\n",
    "    min_percentile=2, # clip the lower 2% of pixel values to enhance contrast\n",
    "    max_percentile=99.9, # clip the upper 0.01% of pixel values to enhance contrast\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918041cc",
   "metadata": {},
   "source": [
    "# Slice a satellite image into squared tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d90ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import slice_raster\n",
    "\n",
    "slice_raster(\n",
    "    raster_in_path=\"data/test_raster_rendered.tif\",\n",
    "    raster_out_dir=\"data/tiles\",\n",
    "    tile_size=512, # square tiles of 512x512 pixels\n",
    "    skip_empty_tiles=True, # skip tiles that are empty (all values are the same, e.g. all zeros)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb53690",
   "metadata": {},
   "source": [
    "# YOLO OBB inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d312f9",
   "metadata": {},
   "source": [
    "### Make YOLO OBB georeferenced predictions over a satellite image using SAHI for slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sahi import AutoDetectionModel\n",
    "from functions import yolo_obb_predict\n",
    "\n",
    "# Load model\n",
    "detection_model = AutoDetectionModel.from_pretrained(\n",
    "    model_type=\"ultralytics\", # Make sure ultralytics is installed: pip install ultralytics\n",
    "    model_path=\"yolo11m-obb.pt\", # This model is trained on DOTAv1 dataset (will be automatically downloaded). Use an OBB model\n",
    "    confidence_threshold=0.2,\n",
    "    device=\"cuda:0\", # use GPU if available, otherwise use \"cpu\"\n",
    ")\n",
    "\n",
    "# Run prediction\n",
    "yolo_obb_predict(\n",
    "    image_file=\"data/test_raster_rendered.tif\", # input georeferenced raster file (e.g. GeoTIFF)\n",
    "    labels_file=\"data/test_raster_rendered.geojson\", # output geojson file with georeferenced bounding boxes\n",
    "    detection_model=detection_model, \n",
    "    tile_size=512, # squared tiles only, size in pixels\n",
    "    overlap_ratio=0.1, # overlap between tiles, value between 0 and 1\n",
    "    classes_to_keep=[1], # Keep only class ID 1 (ship class in DOTAv1 dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fabbebe",
   "metadata": {},
   "source": [
    "### OR make predictions on a set of tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbc9b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load model\n",
    "model = YOLO('yolo11m-obb.pt') # This model is trained on DOTAv1 dataset (will be automatically downloaded)\n",
    "\n",
    "# Process each tile in the directory\n",
    "results = model.predict( # Output in the runs directory by default, e.g. runs/detect/predict/labels\n",
    "    source=\"data/tiles\",\n",
    "    conf=0.01,\n",
    "    save=True, # Set to True to save plots with bounding boxes\n",
    "    save_txt=True,\n",
    "    save_conf=True,\n",
    "    device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90d44e4",
   "metadata": {},
   "source": [
    "# SAM3 inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349d2505",
   "metadata": {},
   "source": [
    "### Make SAM3 predictions on a set of tiles (SAM3 doesn't work with SAHI yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbfd04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from ultralytics.models.sam import SAM3SemanticPredictor\n",
    "\n",
    "DIR_TILES = \"data/tiles\"\n",
    "PROMPTS = [\"motor boat\", \"sailboat\", \"ship\"] # Example text prompts for SAM3\n",
    "\n",
    "# Initialize predictor with configuration\n",
    "overrides = dict(\n",
    "    conf=0.3,\n",
    "    task=\"segment\",\n",
    "    mode=\"predict\",\n",
    "    model=\"/home/luka/Desktop/weights/sam3.pt\", # Instructions for downloading https://docs.ultralytics.com/models/sam-3/#installation\n",
    "    half=True,  # Use FP16 for faster inference\n",
    "    save=False,  # Disable default saving\n",
    "    save_txt=True,  # Save results automatically in run directory\n",
    ")\n",
    "predictor = SAM3SemanticPredictor(overrides=overrides)\n",
    "\n",
    "# Process each tile in the directory\n",
    "list_images = sorted(glob(os.path.join(DIR_TILES, \"*.tif\")))\n",
    "for image_path in list_images:\n",
    "    predictor.set_image(image_path) # Set image for prediction\n",
    "    results = predictor(text=PROMPTS) # Query with a text prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb3436c",
   "metadata": {},
   "source": [
    "### Visualize predictions and save plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032e323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "DIR_TILES = \"data/tiles\"\n",
    "DIR_LABELS = \"runs/segment/predict/labels\"\n",
    "COLORS = [\"yellow\", \"magenta\", \"cyan\", \"red\", \"blue\", \"black\"]\n",
    "\n",
    "out_dir = DIR_LABELS.replace(\"labels\", \"plots\") # Default output directory for plots\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "list_label_files = glob(os.path.join(DIR_LABELS, \"*.txt\"))\n",
    "for label_file in list_label_files:\n",
    "    image_file = os.path.join(DIR_TILES, os.path.basename(label_file).replace(\".txt\", \".tif\"))\n",
    "    print(f\"Image: {image_file}, Label: {label_file}\")\n",
    "\n",
    "    image = cv2.imread(image_file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    height, width, _ = image.shape\n",
    "    plt.imshow(image)\n",
    "\n",
    "    with open(label_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            cls = int(parts[0])\n",
    "            coords = list(map(float, parts[1:]))\n",
    "            x_coords = coords[0::2]\n",
    "            y_coords = coords[1::2]\n",
    "\n",
    "            x_pixels = [x * width for x in x_coords]\n",
    "            y_pixels = [y * height for y in y_coords]\n",
    "\n",
    "            plt.plot(x_pixels + [x_pixels[0]], y_pixels + [y_pixels[0]], color=COLORS[cls % len(COLORS)], linewidth=1)\n",
    "    \n",
    "    plt.savefig(os.path.join(out_dir, os.path.basename(label_file).replace(\".txt\", \".png\")))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "buildings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
